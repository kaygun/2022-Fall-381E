{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e6ba7c-f43d-4dca-8d2f-cd5e0fce5098",
   "metadata": {},
   "source": [
    "# MAT 381, Lecture 12 (Review)\n",
    "\n",
    "\n",
    "## Random Variables\n",
    "\n",
    "All data are sampled from random variables, which are variables whose possible values are outcomes of a random event. They are used to model random phenomena, and can be either discrete or continuous.\n",
    "\n",
    "Discrete random variables can only take on a specific set of values. For example, the number of heads that result from flipping a coin is a discrete random variable, as it can only take on the values 0, 1, or 2 (assuming the coin is not flipped more than twice). A continuous random variable, on the other hand, can take on any value within a certain range. For example, the height of a person is a continuous random variable, as it can take on any value within a certain range (e.g. between 1 foot and 8 feet). \n",
    "\n",
    "Here are several common tasks that we performed with datasets sampled from random variables:\n",
    "\n",
    "\n",
    "* Expected value is a measure of the central tendency of the variable, and is calculated as the sum of the product of each possible value of the variable and its probability. The expected value can be thought of as the average value of the variable.\n",
    "\n",
    "* Variance of a random variable is a measure of its spread or dispersion, and is calculated as the sum of the squared differences between each possible value of the variable and its expected value, divided by the number of possible values. The standard deviation is the square root of the variance, and is a measure of the spread of the variable in terms of its expected value.\n",
    "\n",
    "* Correlation is a measure of the relationship between two random variables. Positive correlation means that the two variables tend to move in the same direction (e.g. as one variable increases, the other variable also increases), while negative correlation means that the two variables tend to move in opposite directions (e.g. as one variable increases, the other variable decreases).\n",
    "\n",
    "* Hypothesis testing is a statistical procedure used to test whether a claim or hypothesis about a population parameter (such as the mean or variance) is true, based on a sample of data drawn from the population. Hypothesis testing involves formulating a null hypothesis (the claim to be tested) and an alternative hypothesis (the claim that the null hypothesis is false), and determining the probability of obtaining the sample data if the null hypothesis is true.\n",
    "\n",
    "\n",
    "## Numerical vs Categorical Data\n",
    "\n",
    "Numerical data and categorical data are two main types of data that we worked with during our course.\n",
    "\n",
    "Numerical data can be measured or quantified, and is represented by numbers, or in general by vectors. Such data can be sampled from a continuous random variable or a discrete radom variable. Continuous numerical data can take on any value within a certain range (e.g. height, weight), while discrete numerical data can only take on specific, distinct values (e.g. the number of students in a class).\n",
    "\n",
    "Categorical data refers to data that can be organized into categories or groups. Categorical data is often represented by text or symbols, and cannot be meaningfully ordered or ranked. Categorical data can be either nominal or ordinal. Nominal categorical data consists of categories that do not have a natural order (e.g. eye color, hair color), while ordinal categorical data consists of categories that have a natural order (e.g. low, medium, high).\n",
    "\n",
    "The differences between numerical and categorical data can have important implications for data analysis tasks. For example:\n",
    "\n",
    "* We use different summary statistics for numerical and categorical data. For numerical data, common summary statistics include mean, median, and standard deviation, while for categorical data, common summary statistics include frequency and percentage.\n",
    "\n",
    "* We use different types of plots for numerical and categorical data. For numerical data, common plots include histograms, scatterplots, and boxplots, while for categorical data, common plots include bar plots and pie charts.\n",
    "\n",
    "* We use different techniques are used for cleaning and preparing numerical and categorical data. For example, missing values in numerical data can often be imputed using techniques such as mean imputation or multiple imputation, while missing values in categorical data may need to be handled differently (e.g. by replacing missing values with a separate category).\n",
    "\n",
    "* We use different models for numerical and categorical data. For example, linear regression and logistic regression are commonly used for numerical and categorical data, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4809c-766a-43c4-a5d7-b432c004ddee",
   "metadata": {},
   "source": [
    "## Structured Data\n",
    "\n",
    "Structured data is data that is organized in a well-defined format, such as a table or a spreadsheet. It typically consists of rows and columns, with each column representing a different attribute or feature of the data, and each row representing a data point or record.\n",
    "\n",
    "There are many different types of structured data, depending on the specific characteristics and purpose of the data. Here are some examples of different structured data types:\n",
    "\n",
    "* Tabular data: Tabular data is data that is organized into a table, with rows representing data points and columns representing attributes or features. Examples of tabular data include data stored in spreadsheet formats (such as CSV or Excel), data stored in a database table, and data organized as a dataframe in a programming language such as Python.\n",
    "\n",
    "* Hierarchical data: Hierarchical data is data that is organized into a tree-like structure, with each data point having one or more child points. Hierarchical data is often used to represent relationships between data points, such as the parent-child relationship between categories in a product catalog.\n",
    "\n",
    "* Graph data: Graph data is data that is organized into a graph structure, with data points representing nodes and relationships between data points represented as edges. Graph data is often used to represent complex relationships between data points, such as social networks or networks of interconnected data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09473b9a-f0fb-44cb-9d27-e8a2a103b703",
   "metadata": {},
   "source": [
    "## Structured Data Types\n",
    "\n",
    "### Tabular/Columnar Data\n",
    "\n",
    "Columnar data is data that is organized into a table-like structure, with rows representing individual observations and columns representing variables or features. Columnar data is a common format for storing and manipulating data in databases, spreadsheets, and other data management systems.\n",
    "\n",
    "One of the main advantages of columnar data is that it allows for efficient querying and manipulation of data using SQL or other query languages. Columnar data is also well-suited for storing and manipulating large datasets, as it allows for fast access to specific columns or subsets of the data without needing to read the entire dataset into memory.\n",
    "\n",
    "In addition to these benefits, columnar data also has some limitations. One potential drawback of columnar data is that it can be difficult to represent complex relationships between variables or to store data with irregular or nested structure. In such cases, other data formats, such as hierarchical data or graph data, may be more suitable.\n",
    "\n",
    "![Land_Slides](./images/land-slides.png)\n",
    "\n",
    "(Image: A sample of landslides that happened in Turkey. Data is from USGS.)\n",
    "\n",
    "During the course we heavily used [UCI's data repository](https://archive.ics.uci.edu/ml/datasets.php) for example datasets, [python](https://www.python.org/) and its tools and libraries for analyzing columnar data. During this course we mostly used [Pandas](https://pandas.pydata.org/). \n",
    "\n",
    "### Time Series Data\n",
    "\n",
    "Time series data is a type of structured data, as it is typically organized into a table or dataframe with rows representing time points and columns representing different variables or attributes. A time series is a sequence of data points that are collected over time. The data is often collected at regular intervals, such as every hour, day, week, or month. Time series data can come from a wide range of sources, such as financial data, sensor data, social media data, and more.\n",
    "\n",
    "![A_Time_Series](./images/time-series.png)\n",
    "\n",
    "(Image: Paleohydrologic reconstructions of water-year streamflow for 31 stream gaging sites in the Missouri River Basin with complete data for 1685 through 1977.)\n",
    "\n",
    "We can analyze time series in different ways, depending on the specific needs of the analysis and the characteristics of the data. Here are some common techniques for analyzing time series data:\n",
    "\n",
    "* Forecasting: Time series forecasting is the process of predicting future values of a time series based on its past values. Forecasting can be useful for predicting future demand, sales, or other quantities of interest, and can be done using a variety of techniques, such as exponential smoothing, autoregressive integrated moving average (ARIMA) models, or machine learning algorithms.\n",
    "\n",
    "* Decomposition: Time series decomposition is the process of breaking down a time series into its component parts, such as trend, seasonality, and noise. Decomposition can be useful for understanding the underlying patterns and trends in the data, and can be used as a preprocessing step for other types of analysis.\n",
    "\n",
    "* Anomaly detection: Time series anomaly detection is the process of identifying unusual or unexpected patterns in a time series. Anomaly detection can be used to identify problems or issues in a system, or to detect fraudulent or unusual behavior in financial or other types of data.\n",
    "\n",
    "* Time series visualization: Time series visualization is the process of creating graphs or plots to visualize the trends and patterns in a time series. Visualization can be useful for identifying trends, spotting anomalies, and communicating the results of time series analysis to others.\n",
    "\n",
    "Python has many tools and libraries available for analyzing time series data. During this course we used [Pandas](https://pandas.pydata.org/), [scikit-learn](https://scikit-learn.org/stable/), [Statsmodels](https://www.statsmodels.org/stable/index.html), and many other libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846a1aa8-3839-4663-bb9a-ec617852fdff",
   "metadata": {},
   "source": [
    "### Network/Graph Data\n",
    "\n",
    "Network data is data that represents relationships or connections between entities or nodes. Network data is typically represented as a graph, with nodes representing the entities and edges representing the relationships between them. There are many different types of data that can be considered as network data, depending on the specific characteristics and purpose of the data. One can analyze such data using techniques such as network centrality, community detection, shortest path analysis, vulnerability analysis, or information diffusion. \n",
    "\n",
    "Here are some examples of different types of network data\n",
    "\n",
    "* Social network \n",
    "* Communication network data\n",
    "* Transportation network data \n",
    "* Infrastructure network data\n",
    "\n",
    "Social network data is data that represents relationships between individuals or groups in a social context. Social network data can be used to study social interactions, influence, and community structure.\n",
    "\n",
    "![GOT](./images/got-characters.png)\n",
    "\n",
    "(Image: A network plot of Game of Thrones characters.)\n",
    "\n",
    "Communication network data is data that represents relationships between individuals or groups based on communication patterns. Communication network data can be used to study information flow, social ties, and collaboration.\n",
    "\n",
    "Transportation network data is data that represents relationships between locations or nodes in a transportation network. Transportation network data can be used to study the connectivity and accessibility of different locations.\n",
    "\n",
    "Infrastructure network data is data that represents relationships between infrastructure assets or nodes in a network. Infrastructure network data can be used to study the interdependencies and vulnerabilities of different assets.\n",
    "\n",
    "The main library we used for network analysis was [networkx](https://networkx.org/). NetworkX is a library for the creation, manipulation, and study of complex networks. It provides a wide range of functions for tasks such as network creation, network visualization, network analysis, and more.  \n",
    "\n",
    "Here are the alternatives:\n",
    "\n",
    "* [igraph](https://igraph.org/) is a library for the creation and analysis of complex networks. It provides a wide range of functions for tasks such as network creation, network visualization, network analysis, and more.\n",
    "\n",
    "* [graph-tool](https://graph-tool.skewed.de/) is a library for the creation, manipulation, and analysis of complex networks. It provides a wide range of functions for tasks such as network creation, network visualization, network analysis, and more, and is optimized for performance.\n",
    "\n",
    "* [snap-stanford](https://pypi.org/project/snap-stanford/) is a library for working with large networks that provides a wide range of functions for tasks such as network creation, network visualization, network analysis, and more. It is built on top of the [Stanford Network Analysis Platform (SNAP)](http://snap.stanford.edu/), and is designed to be efficient and scalable.\n",
    "\n",
    "* [PyGSP](https://pygsp.readthedocs.io/en/stable/) is a library for graph signal processing that provides a wide range of functions for tasks such as graph filtering, graph convolution, and graph spectral analysis. It is built on top of NetworkX and NumPy, and is designed to make it easy to work with graphs and signals in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71788213-dad6-4e64-867f-eb634586c306",
   "metadata": {},
   "source": [
    "### Common Structured Data Formats\n",
    "\n",
    "Here are some data formats we used during the class to work with structured data:\n",
    "\n",
    "1. [Comma Separated Vectors (CSV)](https://en.wikipedia.org/wiki/Comma-separated_values)\n",
    "2. [Javascript Object Notation (JSON)](https://en.wikipedia.org/wiki/JSON) \n",
    "3. [Yet Another Markup Language (YAML)](https://en.wikipedia.org/wiki/YAML) \n",
    "4. [Extensible Markup Language (XML)](https://en.wikipedia.org/wiki/XML)\n",
    "5. [Microsoft Excel Files (XLS,XLSX)](https://docs.fileformat.com/spreadsheet/xls/)\n",
    "6. [MATLAB Binary Data Format (MAT)](https://www.loc.gov/preservation/digital/formats/fdd/fdd000440.shtml)\n",
    "7. [Apache Parquet Files](https://arrow.apache.org/docs/python/parquet.html)\n",
    "8. [Hierarchical Data Format (HDF)](https://en.wikipedia.org/wiki/Hierarchical_Data_Format)\n",
    "\n",
    "![JSON_Example](./images/json-sample.png)\n",
    "\n",
    "(Image: A JSON Example.)\n",
    "\n",
    "### Structured Data Processing Libraries in Python\n",
    "\n",
    "The main library we used for working with structured data was [pandas](https://pandas.pydata.org/). Pandas is a widely used library for data manipulation and analysis in Python. It provides easy-to-use data structures and data analysis tools for handling and manipulating large datasets. pandas is particularly well-suited for working with tabular data, such as data stored in spreadsheet-like formats (e.g. CSV, Excel).\n",
    "\n",
    "Here are some alternatives for pandas:\n",
    "\n",
    "* [Dask](https://docs.dask.org/en/stable/) is a flexible parallel computing library that is built on top of NumPy and pandas. It allows you to scale your data processing and analysis workloads across multiple CPU cores or even distributed across a cluster of machines. Dask is particularly useful for working with large datasets that do not fit into memory, as it can handle data that is stored in external storage (e.g. on disk, in a database) and perform lazy evaluation to avoid reading all data into memory at once.\n",
    "\n",
    "* [DuckDB](https://duckdb.org/2021/05/14/sql-on-pandas.html) is a column-oriented database management system (DBMS) that is designed to be fast and efficient for analytical queries and data processing tasks. It is written in C++ and has a Python API that allows you to use it as a library for data analysis in Python. DuckDB can handle large datasets and is optimized for in-memory and on-disk processing. It supports a SQL-like query language and can be used to perform complex data transformations and aggregations.\n",
    "\n",
    "* [SQLite3](https://docs.python.org/3/library/sqlite3.html) is a lightweight, self-contained database management system (DBMS) that is widely used for data storage and management in many applications. It is written in C and has a simple, easy-to-use API that can be accessed from a variety of programming languages, including Python. SQLite3 can be used to store and manage large datasets, and to perform complex data transformations and aggregations using SQL commands. It can be particularly useful for handling data that is structured in a tabular format, and is often used as a lightweight alternative to more full-featured database management systems, as it does not require a separate server process and can be easily embedded in applications. It is also well-suited for use in environments where data needs to be stored locally (e.g. on a device or in a web browser).\n",
    "\n",
    "* [Vaex](https://vaex.io/) is a high-performance data analysis library for Python that is designed for working with very large datasets (tens of billions of rows). It uses a lazy evaluation model and an optimized in-memory data representation to allow for fast computation and exploration of large datasets without the need to load all data into memory. Vaex supports a wide range of data formats and can be used for tasks such as data filtering, aggregation, and visualization.\n",
    "\n",
    "\n",
    "### Alternatives to Python\n",
    "\n",
    "* [R](https://www.r-project.org/) is a programming language and environment specifically designed for statistical computing and data analysis. It has a large and active user community, and is supported by a wide range of libraries and tools for tasks such as data manipulation, visualization, machine learning, and more.\n",
    "\n",
    "![R_Sample](./images/r-sample.png)\n",
    "\n",
    "* [Julia](https://julialang.org/) is a programming language specifically designed for scientific computing and data analysis. It has a strong focus on performance and efficiency, and is supported by a wide range of libraries and tools for tasks such as numerical optimization, machine learning, and data visualization.\n",
    "\n",
    "![Julia_Sample](./images/julia-sample.png)\n",
    "\n",
    "* [MATLAB](https://www.mathworks.com/products/matlab.html) is a proprietary programming language and environment specifically designed for scientific computing and engineering. It has a wide range of built-in functions and toolboxes for tasks such as data manipulation, visualization, machine learning, and more, and is often used in academia and industry. MATLAB has an open alternative called [Octave](https://octave.org/).\n",
    "\n",
    "![Matlab_Sample](./images/matlab-sample.png)\n",
    "\n",
    "* [Scala](https://www.scala-lang.org/) is a programming language that combines elements of functional programming and object-oriented programming, and is often used in data engineering and big data applications. The main selling point of scala is [Apache Spark](https://spark.apache.org/) which is a nified engine for large-scale data analytics. It has a strong focus on performance and scalability, and desingned specifically for tasks such as data manipulation, machine learning, and data streaming.\n",
    "\n",
    "![Scala_Sample](./images/scala-sample.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf5a7d6-75f1-45c1-aea4-157558986169",
   "metadata": {},
   "source": [
    "## Semi-Structured Data\n",
    "\n",
    "### Geographic/Spatial Data\n",
    "\n",
    "Geographic/Spatial data falls in between structured and unstructured data.  Spatial data is data that represents geographic locations or objects, and is often used in geospatial analysis. Geospatial analysis is the process of analyzing and interpreting data that has a spatial component, and can be used to study patterns, trends, and relationships in data that is geographically distributed.\n",
    "\n",
    "Examples of spatial data include:\n",
    "\n",
    "* Maps\n",
    "* Location data    \n",
    "* Satellite imagery\n",
    "\n",
    "Maps are representations of the Earth's surface or a portion of it, and can be used to show geographic features such as coastlines, rivers, mountains, and cities. Maps can be created in various scales and projections, and can be used to study patterns and trends in data such as population density, land use, or transportation networks.\n",
    "\n",
    "![Besiktas](./images/besiktas.png)\n",
    "\n",
    "(Image: A map of Beşiktaş.)\n",
    "\n",
    "Location data is data that represents the location of objects or devices, and can be used to study patterns and trends in data such as movement, behavior, and mobility. Location data can be collected using various technologies such as GPS, WiFi, or Bluetooth, and can be used to study patterns and trends in data such as transportation patterns, consumer behavior, and social interactions.\n",
    "\n",
    "Satellite imagery is data captured by satellite sensors, and can be used to study the Earth's surface and atmosphere in detail. Satellite imagery can be used to study patterns and trends in data such as land use, vegetation, and land cover.\n",
    "\n",
    "### A List of GIS Formats and Geospatial File Extensions \n",
    "\n",
    "* ESRI Shapefiles (.SHP, .DBF, .SHX): ESRI shapefile is a standard geospatial file format. The\n",
    "folllowing three file types are mandatory for a shapefile: DBF (attribute data), SHP (feature\n",
    "geometry) and SHX (shape index positions). The following files are optional: PRJ (the projection\n",
    "system), SBN (spatial index to optimize queries), and SBX (to optimize file uptake).\n",
    "\n",
    "* Geographic JSON (.GEOJSON, .JSON): GeoJSON is a human-readable data format that encodes data in a\n",
    "variant of JSON which usually has less markup overhead compared to other markup languages GML.\n",
    "\n",
    "* Geography Markup Language (.GML): GML is another human-readable data format. It is a variant of\n",
    "XML, and is very verbose compared to GEOJSON.\n",
    "\n",
    "* Open Street Map Files (.OSM): OSM is another XML-based file format used by the largest\n",
    "crowdsourcing GIS data project in the world.  OSM also uses a smaller alternate format PBF\n",
    "(Protocolbuffer Binary Format) which is again based on XML.\n",
    "\n",
    "* Google Keyhole Markup Language (.KML, .KMZ): This is another XML variant used primarily for\n",
    "Google Earth. There is also a compressed version (KMZ).\n",
    "\n",
    "* GPS exchange format (.GPX): This too is a variant of XML that encodes data captured by GPS\n",
    "receivers, and primarily used for data exchange between GPS software.  GPX records latitude and\n",
    "longitude coordinates, location, time, and elevation.\n",
    "\n",
    "* US Census Bureau file formats: Digital Line Graph (DLG) and Geographic Base File-Dual Independent\n",
    "Mask Encoding (GBF-DIME). DLG files encode information for topographic maps such as contour lines,\n",
    "roads, railroads, towns, and township lines. Much of the U.S. Bureau of Census Topologically\n",
    "Integrated Geographic Encoding and Referencing (TIGER) data stored in DLG format. GBF-DIME format\n",
    "is used mainly for encoding US road network in major urban areas.\n",
    "\n",
    "* ASCII Grid Files (.ASC): ASC files are specially formatted CSV files with a header.\n",
    "\n",
    "* GeoTIFF Files (.TIFF, .OVR): GeoTIFF is a variant of the TIFF format which is originally an image\n",
    "format. Usually GeoTIFF files come with other files: XML (for metadata), TFW (for raster location),\n",
    "AUX (projection information), OVR (to imporove raster display).\n",
    "\n",
    "* ERDAS Image Files (.IMG): IMG format is a hiearchical data format that can store hyperspectral\n",
    "images along with information about ground control points, sensors, or projections.\n",
    "\n",
    "* ESRI Grid Files (.ADF): ADF files encode data in a grid. The grid can be an integer grid (such as\n",
    "land cover) or floating point grid (such as elevation.) Attribute data usually is stored alongside\n",
    "in a separate file.\n",
    "\n",
    "* ENVI Raster Files (.BIL, .BIP, .BSQ): Band Interleaved data files come in 3 varieties. These\n",
    "varieties encode hyperspectral images by lines, by pixel, and by sequence. They usually come with a\n",
    "separate header file (HDR) that contains some metadata for the images such as size, depth, layout\n",
    "etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d4926e-3b60-407d-85f3-701ab6f62014",
   "metadata": {},
   "source": [
    "## Unstructured Data\n",
    "\n",
    "In this course we worked with the following main classes of unstructured data:\n",
    "\n",
    "1. Text data\n",
    "2. Image data\n",
    "3. Audio data\n",
    "\n",
    "### Text Data\n",
    "\n",
    "Text data refers to data that is in the form of written or spoken language. It can include text documents, social media posts, transcripts of audio or video recordings, and any other type of data that consists of words and sentences.\n",
    "\n",
    "![Word_Cloud](./images/word-cloud.png)\n",
    "\n",
    "There are many different ways to process and analyze text data, depending on the specific goals of the analysis and the characteristics of the data. Here are some common approaches:\n",
    "\n",
    "* Text classification is the process of assigning a label or category to a piece of text based on its content. Text classification can be used for tasks such as spam filtering, sentiment analysis, or topic identification.\n",
    "\n",
    "* Summarization refers to the process of generating a concise and coherent summary of a text or a collection of texts. Summarization can be performed at various levels of granularity, ranging from a summary of a single sentence to a summary of an entire document or a corpus of documents. Summarization is an important task in natural language processing, as it allows people to quickly understand the main points or ideas expressed in a text. It is also useful for tasks such as information retrieval, where a summary of a document can help users understand the content of the document without having to read the entire document.\n",
    "\n",
    "* Sentiment analysis is about determining the emotional tone or sentiment of a piece of text. It can be used to classify text as positive, negative, or neutral, and can be useful for understanding how people feel about a particular topic or product.\n",
    "\n",
    "* Keyword extraction is the process of automatically identifying and extracting the most relevant and important words or phrases from a text. Keywords are typically used to summarize the content of a text, to facilitate search and retrieval, or to support tasks such as text classification or topic modeling.\n",
    "\n",
    "* Named entity recognition (NER) algorithms identify and classify named entities (e.g. people, organizations, locations) in a piece of text. NER can be useful for extracting structured information from unstructured text and can be used for tasks such as information extraction or text summarization.\n",
    "\n",
    "* Author attribution is the process of determining the identity of the author of a text based on their writing style or other linguistic characteristics. It is often used in tasks such as plagiarism detection, forensic linguistics, and literary analysis, and can be based on various types of linguistic features, including vocabulary, syntax, and structure. There are many approaches to author attribution, including rule-based systems, machine learning-based systems, and hybrid systems. Machine learning-based systems are often based on techniques such as clustering, classification, and feature selection, and have achieved good performance on a wide range of tasks.\n",
    "\n",
    "* Part-of-speech (POS) taggers are algorithmic devices that assign a grammatical category (e.g. noun, verb, adjective) to each token in a piece of text. POS tagging can be useful for understanding the structure and meaning of the text, and can be used as a preprocessing step for other tasks such as named entity recognition or sentiment analysis.\n",
    "\n",
    "There are many tools and libraries available for processing and analyzing text data in Python. Some popular ones include [Natural Language Toolkit (NLTK)](https://www.nltk.org/), [spaCy](https://spacy.io/), [Gensim](https://radimrehurek.com/gensim/), and [Classical Language Toolkit (CLTK)](http://cltk.org/). These libraries provide a wide range of functions for tasks such as tokenization, POS tagging, NER, sentiment analysis, and text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df4127-f79a-4a28-b1a2-6f492516ff6f",
   "metadata": {},
   "source": [
    "### Image Data\n",
    "\n",
    "Image data is data that represents visual information, such as photographs, videos, or other types of images. Image data can be either raster or vector.\n",
    "\n",
    "Raster image data is data that is represented as a grid of pixels, with each pixel representing a different color or intensity value. Raster images are often stored in formats such as JPEG, PNG, or TIFF, and are well-suited for representing continuous-tone images such as photographs.\n",
    "\n",
    "Vector image data is data that is represented as a set of points, lines, and curves, with each element defined mathematically. Vector images are often stored in formats such as SVG, and are well-suited for representing graphics and text.\n",
    "\n",
    "\n",
    "| Abbreviation | File format                           | File extension(s)                | Summary             |  \n",
    "|--------------|---------------------------------------|:--------------------------------:|:--------------------|\n",
    "| GIF          | Graphics Interchange Format           | .gif                             | Good choice for simple images and animations. Prefer PNG for lossless and indexed still images, and consider WebP, AVIF or APNG for animation sequences.                                                                         |\n",
    "| JPEG         | Joint Photographic Expert Group image | .jpg, .jpeg, .jfif, .pjpeg, .pjp | Good choice for lossy compression of still images (currently the most popular). Prefer PNG when more precise reproduction of the image is required. |\n",
    "| PNG          | Portable Network Graphics             | .png                             | PNG is preferred over JPEG for more precise reproduction of source images, or when transparency is needed. |\n",
    "| SVG          | Scalable Vector Graphics              | .svg                             | Vector image format; ideal for user interface elements, icons, diagrams, etc., that must be drawn accurately at different sizes.   |\n",
    "| BMP          | Bitmap file                           | .bmp                           |  The BMP (Bitmap image) file type is most prevalent on Windows computers, and is generally used only for special cases in web apps and content. |\n",
    "| TIFF         | Tagged Image File Format              | .tif, .tiff                    |TIFF is a raster graphics file format which was created to store scanned photos, although it can be any kind of image. |\n",
    "\n",
    "The table above is taken from [here](https://developer.mozilla.org/en-US/docs/Web/Media/Formats/Image_types#common_image_file_types) with some modifications.\n",
    "\n",
    "Image data is often used in a wide range of applications, such as computer vision, image processing, and machine learning. Some common types of analyses that can be performed on image data include:\n",
    "\n",
    "* Image classification: Image classification is the process of assigning a label or category to an image based on its content. Image classification can be used for tasks such as object detection or scene understanding, and can be performed using machine learning algorithms or other techniques.\n",
    "\n",
    "* Object detection: Object detection is the process of identifying and locating objects in an image. Object detection can be used for tasks such as autonomous driving or image tagging, and can be performed using machine learning algorithms or other techniques.\n",
    "\n",
    "* Image segmentation: Image segmentation is the process of dividing an image into regions or segments based on certain criteria, such as color, texture, or shape. Image segmentation can be used for tasks such as object recognition or image manipulation, and can be performed using machine learning algorithms or other techniques.\n",
    "\n",
    "* Optical character recognition (OCR): OCR is the process of segmenting and extracting text from a picture that contains an image of a text. OCR systems typically work by analyzing the image of a document and recognizing the individual characters in the text using pattern recognition algorithms and machine learning models. The recognized text is then output as a machine-readable format, such as ASCII or Unicode text, which can be further processed or analyzed.  \n",
    "\n",
    "* Image restoration: Image restoration is the process of repairing or enhancing an image that has been damaged or degraded in some way. Image restoration can be used to remove noise, blur, or other distortions from an image, and can be performed using techniques such as filtering, interpolation, or image inpainting.\n",
    "\n",
    "There are many libraries available for image processing tasks in Python. Some popular ones include:\n",
    "\n",
    "1. [OpenCV (Open Computer Vision)](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html) is a widely-used library for image processing and computer vision tasks. It provides a wide range of functions for tasks such as image acquisition, image filtering, image transformation, object detection, and more.\n",
    "\n",
    "2. [Pillow](https://pillow.readthedocs.io/en/stable/) is a fork of the Python Imaging Library (PIL), and is a widely-used library for working with image data in Python. It provides functions for tasks such as reading and writing image files, manipulating images, and applying image filters.\n",
    "\n",
    "3. [Scikit-image](https://scikit-image.org/) is a library for image processing and computer vision tasks that is built on top of NumPy and SciPy. It provides a wide range of functions for tasks such as image filtering, image segmentation, image feature extraction, and more.\n",
    "\n",
    "4. [Imutils](https://github.com/PyImageSearch/imutils) is a library that provides a set of convenience functions for tasks such as image resizing, image translation, and image rotation. It is built on top of OpenCV and is designed to make common image processing tasks easy to perform.\n",
    "\n",
    "## Image Data for Teaching, Experiments and Research\n",
    "\n",
    "![Olivetti_Faces](./images/olivetti.png)\n",
    "\n",
    "(Image: A sample from Olivetti Faces Dataset.)\n",
    "\n",
    "1. [MNIST](http://yann.lecun.com/exdb/mnist/)\n",
    "1. [Extended MNIST](https://www.kaggle.com/datasets/crawford/emnist)\n",
    "1. [Fashion MNIST](https://www.kaggle.com/datasets/zalando-research/fashionmnist)\n",
    "1. [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist)\n",
    "1. [IMAGENET](https://image-net.org/update-mar-11-2021.php)\n",
    "1. [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "3. [Olivetti Faces Dataset](https://scikit-learn.org/0.19/datasets/olivetti_faces.html)\n",
    "4. [Labeled Faces in the Wild Dataset](http://vis-www.cs.umass.edu/lfw/)\n",
    "5. [Large-scale CelebFaces Attributes (CelebA) Dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)\n",
    "5. [Face Recognition Technology (FERET)](https://www.nist.gov/programs-projects/face-recognition-technology-feret)\n",
    "6. [iMaterialist Competition - Fashion](https://github.com/visipedia/imat_comp)\n",
    "7. [DeepFashion2 Dataset](https://github.com/switchablenorms/DeepFashion2)\n",
    "5. [102 Category Flower Dataset](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html)\n",
    "6. [Comprehensive Plant Image Dataset](https://www.quantitative-plant.org/dataset)\n",
    "3. [Caltech-UCSD Birds Dataset](https://vision.cornell.edu/se3/caltech-ucsd-birds-200/)\n",
    "5. [The Oxford-IIIT Pet Image Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)\n",
    "7. [Stanford Dog Images Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/)\n",
    "8. [Fishnet Open Images Dataset](https://www.fishnet.ai/download)\n",
    "9. [LEGO Bricks Image Dataset](https://www.kaggle.com/datasets/joosthazelzet/lego-brick-images)\n",
    "1. [The Comprehensive Cars (CompCars) dataset](http://mmlab.ie.cuhk.edu.hk/datasets/comp_cars/index.html)\n",
    "2. [Stanford Car Images Dataset](http://ai.stanford.edu/~jkrause/cars/car_dataset.html)\n",
    "1. [LabelMe Dataset](http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php)\n",
    "\n",
    "![MNIST](./images/mnist-sample.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a7ee6-681c-4dbc-b2fe-b93b0c82b4ca",
   "metadata": {},
   "source": [
    "### Audio Data\n",
    "\n",
    "Audio data is data that represents sound or audio, such as music, speech, or other sounds. Audio data is typically stored in a digital format, such as MP3, WAV, or AIFF, and can be played back using audio software or hardware.\n",
    "\n",
    "#### A list of audio file formats\n",
    "\n",
    "<p>(Source: <a\n",
    "href=\"https://en.wikipedia.org/wiki/Audio_file_format\">Wikipedia</a>)</p>\n",
    "<table>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th>Extension</th>\n",
    "<th style=\"text-align: left;\">Explanation</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"odd\">\n",
    "<td><code>.aac</code></td>\n",
    "<td style=\"text-align: left;\">The Advanced Audio Coding format is based\n",
    "on the MPEG-2 and MPEG-4 standards. AAC files are usually ADTS or ADIF\n",
    "containers.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><code>.aiff</code></td>\n",
    "<td style=\"text-align: left;\">A standard uncompressed CD-quality, audio\n",
    "file format used by Apple. Established 3 years prior to Microsoft’s\n",
    "uncompressed version wav.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td><code>.au</code></td>\n",
    "<td style=\"text-align: left;\">The standard audio file format used by\n",
    "Sun, Unix and Java. The audio in au files can be PCM or compressed with\n",
    "the μ-law, a-law or G729 codecs.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><code>.flac</code></td>\n",
    "<td style=\"text-align: left;\">A file format for the Free Lossless Audio\n",
    "Codec, an open-source lossless compression codec.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td><code>.m4a</code></td>\n",
    "<td style=\"text-align: left;\">An audio-only MPEG-4 file, used by Apple\n",
    "for unprotected music downloaded from their iTunes Music Store. Audio\n",
    "within the m4a file is typically encoded with AAC, although lossless\n",
    "ALAC may also be used.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><code>.m4b</code></td>\n",
    "<td style=\"text-align: left;\">An Audiobook / podcast extension with AAC\n",
    "or ALAC encoded audio in an MPEG-4 container. Both M4A and M4B formats\n",
    "can contain metadata including chapter markers, images, and hyperlinks,\n",
    "but M4B allows “bookmarks” (remembering the last listening spot),\n",
    "whereas M4A does not.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td><code>.m4p</code></td>\n",
    "<td style=\"text-align: left;\">A version of AAC with proprietary Digital\n",
    "Rights Management developed by Apple for use in music downloaded from\n",
    "their iTunes Music Store and their music streaming service known as\n",
    "Apple Music.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td><code>.mmf</code></td>\n",
    "<td style=\"text-align: left;\">A Samsung audio format that is used in\n",
    "ringtones. Developed by Yamaha (SMAF stands for “Synthetic music Mobile\n",
    "Application Format”, and is a multimedia data format invented by the\n",
    "Yamaha Corporation, .mmf file format).</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><code>.mp3</code></td>\n",
    "<td style=\"text-align: left;\">MPEG Layer III Audio. It is the most\n",
    "common sound file format used today.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td><code>.ogg</code>, <code>.oga</code>, <code>.mogg</code></td>\n",
    "<td style=\"text-align: left;\">A free, open source container format\n",
    "supporting a variety of formats, the most popular of which is the audio\n",
    "format Vorbis. Vorbis offers compression similar to MP3 but is less\n",
    "popular. Mogg, the “Multi-Track-Single-Logical-Stream Ogg-Vorbis”, is\n",
    "the multi-channel or multi-track Ogg file format.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><code>.opus</code></td>\n",
    "<td style=\"text-align: left;\">A lossy audio compression format developed\n",
    "by the Internet Engineering Task Force (IETF) and made especially\n",
    "suitable for interactive real-time applications over the Internet. As an\n",
    "open format standardised through RFC 6716, a reference implementation is\n",
    "provided under the 3-clause BSD license.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td><code>.raw</code></td>\n",
    "<td style=\"text-align: left;\">A raw file can contain audio in any format\n",
    "but is usually used with PCM audio data. It is rarely used except for\n",
    "technical tests.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><code>.wav</code></td>\n",
    "<td style=\"text-align: left;\">Standard audio file container format used\n",
    "mainly in Windows PCs. Commonly used for storing uncompressed (PCM),\n",
    "CD-quality sound files, which means that they can be large in\n",
    "size—around 10 MB per minute. Wave files can also contain data encoded\n",
    "with a variety of (lossy) codecs to reduce the file size (for example\n",
    "the GSM or MP3 formats). Wav files use a RIFF structure.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td><code>.wma</code></td>\n",
    "<td style=\"text-align: left;\">Windows Media Audio format, created by\n",
    "Microsoft. Designed with Digital Rights Management (DRM) abilities for\n",
    "copy protection.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><code>.webm</code></td>\n",
    "<td style=\"text-align: left;\">Royalty-free format created for HTML5\n",
    "video.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b79d0-62b2-4387-9224-dffbd43ca421",
   "metadata": {},
   "source": [
    "Audio data is similar to other types of time series data in that it is a sequence of data points collected over time. However, there are some characteristics of audio data that make it different from other types of time series data:\n",
    "\n",
    "![Wavelet_Transform](./images/spectrogram.png)\n",
    "\n",
    "(Image: [Source](https://www.researchgate.net/figure/The-result-of-the-continuous-wavelet-transform-Bluish-colors-represent-low-energy_fig6_258623566))\n",
    "\n",
    "* Frequency: Audio data is typically collected at a much higher frequency than other types of time series data. For example, a typical audio file may be sampled at a rate of 44,100 samples per second, while other types of time series data may be sampled at much lower frequencies (e.g. hourly, daily, monthly).\n",
    "\n",
    "* Amplitude: Audio data also has a different range of values than other types of time series data. Audio data is typically represented as a waveform, with the amplitude of the waveform representing the volume or intensity of the sound. The range of possible amplitudes in audio data is typically much larger than the range of values in other types of time series data.\n",
    "\n",
    "* Spectral content: Audio data also has a different spectral content than other types of time series data. The spectral content of audio data refers to the distribution of energy across different frequencies, and is often represented using a spectrogram or other visualization. The spectral content of audio data can vary widely depending on the type of sound being recorded, and can be used to distinguish different types of sounds or music.\n",
    "\n",
    "There are many libraries available for audio processing in Python. Some popular ones include:\n",
    "\n",
    "1. [Librosa](https://librosa.org/doc/latest/index.html) is a library for audio and music analysis that provides a wide range of functions for tasks such as audio loading, audio feature extraction, and audio synthesis. It is built on top of [NumPy](https://numpy.org/) and [SciPy](https://scipy.org/), and is designed to be easy to use and extend.\n",
    "\n",
    "2. [PyAudio](https://people.csail.mit.edu/hubert/pyaudio/) is a library for working with audio in Python that provides functions for tasks such as audio recording and playback, audio file input and output, and audio signal processing. It is built on top of [PortAudio](http://www.portaudio.com/), a cross-platform audio I/O library.\n",
    "\n",
    "3. [scipy.signal](https://docs.scipy.org/doc/scipy/tutorial/signal.html) is the signal module in [SciPy](https://scipy.org/) that is designed for signal processing tasks, and provides functions for tasks such as filtering, convolution, and spectral analysis. It is built on top of [NumPy](https://numpy.org/) and is optimized for performance.\n",
    "\n",
    "4. [pydub](https://github.com/jiaaro/pydub) is a library for working with audio in Python that provides functions for tasks such as audio file loading, audio file manipulation, and audio file output. It is built on top of [ffmpeg](https://ffmpeg.org/), and supports a wide range of audio file formats.\n",
    "\n",
    "5. [soundfile](https://pysoundfile.readthedocs.io/en/latest/) is a library for reading and writing audio files in Python that provides functions for tasks such as audio file loading, audio file manipulation, and audio file output. It is built on top of [libsndfile](http://www.mega-nerd.com/libsndfile/), and supports a wide range of audio file formats.\n",
    "\n",
    "\n",
    "Here are some examples of analyses that can be performed on sound data:\n",
    "\n",
    "* Speech recognition \n",
    "* Music analysis\n",
    "* Sound classification \n",
    "* Audio restoration\n",
    "* Audio synthesis\n",
    "\n",
    "![A_Chromagraph](./images/chromagraph.png)\n",
    "\n",
    "Speech recognition is the process of converting spoken language into written text, and is often used in tasks such as voice-to-text transcription, voice commands, and language translation. Music analysis is the study and interpretion of music, and can be used to study patterns and trends in data such as music structure, melody, harmony, and rhythm. Sound classification is used for identifying the type or category of a sound, audio event detection, sound scene classification, and audio tagging. Audio restoration is about repairing or improving the quality of audio signals, and can be used to remove noise, improve clarity, or restore damaged audio. Finally, audio synthesis is about generating audio signals using algorithms or models, and can be used to create artificial sounds or to synthesize music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83410e-972e-49ef-858d-24800c515f2c",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Data visualization is an important aspect of data analysis and interpretation.  It allows us to explore and understand data in a visual format. There are different types of visualizations that we can use to represent data, each with its own strengths and limitations. Here are a few examples of common types of visualizations:\n",
    "\n",
    "* Line plots: Line plots are used to visualize data that is measured over a continuous interval or time period. Line plots are useful for showing trends and changes in data over time.\n",
    "\n",
    "![A_Line_Plot](./images/line-plot.png)\n",
    "\n",
    "(Image: Average water level from Jan to Dec at Terkos Lake in Istanbul)\n",
    "\n",
    "* Bar charts: Bar charts are used to visualize data that is divided into categories or groups. Bar charts are useful for comparing the size or frequency of different categories.\n",
    "\n",
    "![A_Bar_Chart](./images/bar-chart.png)\n",
    "\n",
    "* Pie charts: Pie charts are used to visualize data that is divided into categories or groups, and are useful for showing the relative sizes of different categories.\n",
    "\n",
    "![A_Pie_Chart](./images/pie-chart.png)\n",
    "\n",
    "* Scatter plots: Scatter plots are used to visualize the relationship between two numerical variables. Scatter plots are useful for showing trends and patterns in data.\n",
    "\n",
    "![A_Scatter_Plot](./images/scatter-plot.png)\n",
    "\n",
    "* Heat maps: Heat maps are used to visualize the values of a numerical variable across a grid of cells. Heat maps are useful for showing patterns and trends in data, and can be used to represent data that is structured in two dimensions.\n",
    "    \n",
    "![A_Heat_Map](./images/heat-map.png)\n",
    "\n",
    "(Source: [Indifoot](https://www.indifoot.com/blog/what-is-a-heat-map-and-why-it-has-become-essential-in-the-current-sports-industry))\n",
    "    \n",
    "* Box plots: Box plots are used to visualize the distribution of a numerical variable. Box plots are useful for showing the range, median, and quartiles of a dataset.\n",
    "\n",
    "![A_Box_Plot](./images/box-plot.png)\n",
    "\n",
    "(Source: [Statistics Canada](https://www150.statcan.gc.ca/n1/edu/power-pouvoir/ch12/5214889-eng.htm))\n",
    "\n",
    "* Maps: \n",
    "\n",
    "![A_Map](./images/turkish-crime.png)\n",
    "\n",
    "(Image: Homicide rates in Turkey 100K people.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b625a57a-ab63-4c8b-8822-04357f5fab8b",
   "metadata": {},
   "source": [
    "### Open Real-Data Sources\n",
    "\n",
    "Large part of doing data science is working with data: cleaning, understanding, filtering, and tranforming it. But in order to do that we need data. Unless you collect your own data, you will need to find interesting data sets that you can understand and ask questions about. Today, we are going to look at possible data sources and their uses.\n",
    "\n",
    "An [application programming interface (API)](https://en.wikipedia.org/wiki/API) is a data connection between two pieces of software. For our purposes, it is a connection between a data consumer (you) and data provider.  Its primary function is **not** to provide data for human consumption, rather it is for exchanging data between two computer programs. In short, you'll use an API to fetch the data not to look at it in its raw form.\n",
    "\n",
    "There are many open data sources that serve data via APIs, allowing you to programmatically access and retrieve data for your data science projects. Here are a few examples of open data sources that provide APIs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6107e-a81f-409f-912d-54be251ea1b1",
   "metadata": {},
   "source": [
    "#### Government Data Providers\n",
    "\n",
    "* [UN Data](https://data.un.org/) \n",
    "* [World Bank Open Data platform](https://data.worldbank.org/) \n",
    "* [European Union Open Data Portal](https://data.europa.eu/en) \n",
    "* [IMF Data platform](https://data.imf.org/) \n",
    "* [European Central Bank](https://sdw.ecb.europa.eu/)\n",
    "* [OECD data](https://data.oecd.org/)\n",
    "* [US Government (data.gov)](https://data.gov) \n",
    "* [UK Government Data](https://www.data.gov.uk/)\n",
    "* [US Central Bank (FED) data](https://fred.stlouisfed.org/)\n",
    "* [Turkish Statistical Corporation TUIK](https://data.tuik.gov.tr/)\n",
    "* [US Census Data](https://www.census.gov/data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fcaf8-a407-4eef-8b6e-e4865cb248ee",
   "metadata": {},
   "source": [
    "#### Municipality Data\n",
    "\n",
    "* [Istanbul Municipality](https://data.ibb.gov.tr/)\n",
    "* [Izmir Municipality](https://acikveri.bizizmir.com/)\n",
    "* [Bursa Municipality](https://acikyesil.bursa.bel.tr/dataset/)\n",
    "* [Athens Open Data](http://geodata.gov.gr/en/dataset)\n",
    "* [Barcelona Municipality](https://opendata-ajuntament.barcelona.cat/)\n",
    "* [London Data Store](https://data.london.gov.uk/developers/)\n",
    "* [New York Open Data](https://opendata.cityofnewyork.us/)\n",
    "* [City of Montreal Open Data](https://donnees.montreal.ca/collections)\n",
    "* [City of Toronto Open Data](https://open.toronto.ca/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623d320-92de-40a5-9f2d-d16605c20f39",
   "metadata": {},
   "source": [
    "#### Health Data\n",
    "\n",
    "* [World Health Organization](https://www.who.int/data/gho/)\n",
    "* [UK National Health System Data](https://digital.nhs.uk/)\n",
    "* [US Health Data](https://healthdata.gov/)\n",
    "* [US Food and Drug Administration (FDA)](https://www.fda.gov/food)\n",
    "* [US National Cancer Institute](https://seer.cancer.gov/statistics-network/explorer/application.html)\n",
    "* [US Centers for Disease Control](https://www.cdc.gov/datastatistics/)\n",
    "\n",
    "#### Scientific Data\n",
    "\n",
    "* [US Geographical Survey (USGS)](https://www.usgs.gov/products/data)\n",
    "* [US National Aeronautics and Space Administration (NASA)](https://data.nasa.gov/)\n",
    "* [European Space Agency (ESA)](https://www.esa.int/)\n",
    "* [US National Oceanic and Atmospheric Administration (NOAA)](https://data.noaa.gov/datasetsearch/)\n",
    "* [Open Science Data Cloud (OSDC)](https://www.opensciencedatacloud.org/)\n",
    "\n",
    "#### Physiological Data\n",
    "\n",
    "* [Open Neuro](https://openneuro.org/)\n",
    "* [PhysioNet](https://physionet.org/about/database/)\n",
    "* [Fall Detection Dataset](https://imvia.u-bourgogne.fr/en/database/fall-detection-dataset-2.html)\n",
    "* [KFall Dataset](https://sites.google.com/view/kfalldataset)\n",
    "* [MM Fit Dataset](https://mmfit.github.io/)\n",
    "* [A collection of body accelerometer datasets](https://mobilize.stanford.edu/data/available-datasets/)\n",
    "\n",
    "#### Sociological Survey Data\n",
    "\n",
    "* [GSS Survey fro U. Chicago](https://gss.norc.org/)\n",
    "* [PEW Research Center](https://www.pewresearch.org/internet/datasets/)\n",
    "* [US National Survey of Families and Households](https://www.ssc.wisc.edu/nsfh/home.htm)\n",
    "* [A collection of open survey data](https://hbl.gcc.libguides.com/soci377/data)\n",
    "\n",
    "#### A List of GIS Data Sources\n",
    "\n",
    "* [UN Geospatial Hub](https://geoservices.un.org/webapps/geohub/)\n",
    "* [Natural Earth](https://www.naturalearthdata.com/)\n",
    "* [Open Street Map](https://www.openstreetmap.org/)\n",
    "* [Global Map](https://www.gsi.go.jp/kankyochiri/globalmap_e.html)\n",
    "* [Libre Map Project](http://libremap.org/)\n",
    "* [Open Topography Project](https://opentopography.org/)\n",
    "* [Infrastructure for Spatial Information in the European Community](http://inspire.jrc.ec.europa.eu/)\n",
    "* [European Environmental Agency](https://www.eionet.europa.eu/workspace/gis)\n",
    "* [GeoSpacial Data from Government of Canada](http://www.geogratis.gc.ca/)\n",
    "\n",
    "#### A List of Satellite Imagery Data Sources\n",
    "\n",
    "* [NASA Earth Data](https://worldview.earthdata.nasa.gov/)\n",
    "* [ESA Earth Data](https://earth.esa.int/eogateway/catalog)\n",
    "* [USGS Earth Explorer](https://earthexplorer.usgs.gov/)\n",
    "* [Copernicus Open Access Hub](https://scihub.copernicus.eu/dhus/#/home)\n",
    "* [NOAA Earth Data](https://coast.noaa.gov/dataviewer/#)\n",
    "* [Bhuvan Indian Geo-Platform of ISRO](https://bhuvan-app3.nrsc.gov.in/data/download/index.php)\n",
    "* [Maxar Open Data](https://www.maxar.com/open-data)\n",
    "\n",
    "#### Other data providers\n",
    "\n",
    "* [Google Public Data Explorer](https://www.google.com/publicdata/directory) and [Google Public Data API Explorer](https://developers.google.com/apis-explorer) are platforms for exploring and visualizing public data sets, and provide links for accessing data in various formats (including CSV, JSON, and KML).\n",
    "* [Humanitarian Data Exchange (HDX)](https://data.humdata.org/) is an open platform for sharing data across crises and organisations.\n",
    "* [Data World](https://docs.data.world/index.html?lang=en) is a third party data provider and storage service.\n",
    "* [DBpedia](https://www.dbpedia.org/) is a crowd-sourced community effort to extract structured content from the information created in various Wikimedia projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9bcc5-b842-45db-84ed-a0348a405e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
